# ğŸ“Œ Text Mining & Topic Modeling auf Consumer Complaints

Dieses Projekt dient der semantischen Analyse und dem Themen-Extrahieren aus einem Kaggle-Datensatz mit Verbraucherbeschwerden (â€Consumer Complaintsâ€œ).
Es kombiniert Vektorisierungstechniken (Bag-of-Words, TF-IDF) mit Themenmodellierungsmethoden (Latente Semantische Analyse (LSA) und Latent Dirichlet Allocation (LDA)).

---

## ğŸš€ Features

- Automatischer Download und Versionierung des Consumer Complaint Datensatzes von Kaggle.

- Preprocessing Pipeline:
    - Tokenisierung
    - Stopword-Entfernung
    - Lemmatisierung

- Vektorisierung von Texten mit:
    - Bag-of-Words (BoW)
    - TF-IDF

- Vergleich von BoW und TF-IDF:
    - HÃ¤ufigkeiten vs. gewichtete Relevanz
    - Euklidische Distanz zwischen Dokumenten

- Themenanalyse mit:
    - Latente Semantische Analyse (LSA) â†’ Dimensionsreduktion mit SVD
    - Latent Dirichlet Allocation (LDA) â†’ probabilistisches Modell mit Themenwahrscheinlichkeiten

- Ausgabe von Top-WÃ¶rtern pro Thema inkl. prozentualer Verteilung.

---

## ğŸ“‚ Projektstruktur

```bash
example.env
run.py  
main/
â”‚â”€â”€ dataset_loader.py     # Download von Kaggle-DatensÃ¤tzen
â”‚â”€â”€ preprocessor.py       # Textbereinigung, Tokenisierung, Lemmatisierung
â”‚â”€â”€ topic_models.py       # LSA- und LDA-Analyzer
â”‚â”€â”€ utils.py              # Hilfsfunktionen (Distanzen, Vergleich, Laden)
â”‚â”€â”€ vectorizers.py        # BoW- und TF-IDF-Vectorizer
```

---

## âš™ï¸ Installation & Setup

### 1. Repository klonen  
```bash
git clone https://github.com/TimRhr/NLP-DataAnalysis.git
cd NLP-DataAnalysis
```

### 2. Virtuelle Umgebung erstellen & aktivieren
```bash
python -m venv .venv
```
```bash
source .venv/bin/activate   # Linux / macOS
```
```bash
.venv\Scripts\activate      # Windows
```

### 3. AbhÃ¤ngigkeiten installieren
```bash
pip install -r requirements.txt
```

### .env Datei konfigurieren (Beispiel siehe example.env):
```ini
# Kaggle API credentials
KAGGLE_USERNAME=dein_name
KAGGLE_KEY=dein_key

# Preprocessing
MAX_FEATURES=100
MAX_TOKENS=50
MAX_ROWS=0
COLUMN_NAME=narrative

# Topic Modeling
N_LSA_TOPICS=5
N_LDA_TOPICS=5
N_WORDS_PER_TOPIC=8
COMPARE_DOC_IDX=5
```

## â–¶ï¸ Nutzung
Das Hauptskript starten:

```bash
python run.py
```

Ablauf:
1. Dataset herunterladen (falls nicht vorhanden).
2. Preprocessing durchfÃ¼hren oder gecachte Version laden.
3. BoW und TF-IDF Vektorisierungen erstellen.
4. Vergleich der Features zwischen BoW und TF-IDF fÃ¼r ein Dokument (COMPARE_DOC_IDX).
5. Euklidische Distanzen zwischen Dokumenten berechnen.
6. Semantische Analyse mit LSA und LDA zur Extraktion der Themen im Korpus.

## ğŸ§  Interpretation

- BoW vs TF-IDF:
    - BoW zeigt absolute WorthÃ¤ufigkeiten, TF-IDF hebt kontextuell relevante WÃ¶rter hervor.
    - Ein Wort mit hoher BoW, aber niedrigem TF-IDF â†’ hÃ¤ufig, aber wenig aussagekrÃ¤ftig.
    - Ein Wort mit niedriger BoW, aber hohem TF-IDF â†’ selten, aber charakteristisch fÃ¼r das Dokument.

- DokumentenÃ¤hnlichkeit:
    - Niedrige Distanzen â†’ Dokumente inhaltlich Ã¤hnlich.
    - Hohe Distanzen â†’ unterschiedliche Themen oder Fokus.

- Themenanalyse:
    - LSA: Zeigt Muster und ZusammenhÃ¤nge zwischen WÃ¶rtern, eher latente Strukturen. Negative Werte reflektieren GegensÃ¤tze oder Abwesenheit im Thema.
    - LDA: Liefert klare, probabilistische Themen. Werte geben die relative Bedeutung jedes Wortes im Thema an.

- Coherence Scores: Helfen bei der Beurteilung, ob die extrahierten Themen sinnvoll und inhaltlich konsistent sind.
